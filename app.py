import streamlit as st
import pandas as pd
from langchain_groq import ChatGroq
from langchain_community.vectorstores import FAISS
from langchain_huggingface import HuggingFaceEmbeddings
from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder
from langchain_core.runnables import RunnablePassthrough
from langchain_core.output_parsers import StrOutputParser

st.set_page_config(page_title="í”„ë¦¬ë¯¸ì—„ AI ë„ì„œê´€", page_icon="ğŸ“š")
st.title("ğŸ“š ì§€ëŠ¥ì€ ë†’ê³  ì†ë„ëŠ” ë¹ ë¥¸ AI ì‚¬ì„œ")
st.caption("ì¶”ì²œ ë°›ê³ ì í•˜ëŠ” ì£¼ì œë¥¼ ì„¤ëª…í•˜ë©´ 3ê°€ì§€ì˜ ì±…ì„ ì¶”ì²œí•´ì¤ë‹ˆë‹¤.")

# 1. ë¦¬ì†ŒìŠ¤ ë¡œë“œ (ìºì‹± ì ìš©)
@st.cache_resource
def load_resources():
    model_name = "intfloat/multilingual-e5-small"
    encode_kwargs = {'normalize_embeddings': True}
    embeddings = HuggingFaceEmbeddings(model_name=model_name, encode_kwargs=encode_kwargs)
    
    vector_db = FAISS.load_local("faiss_book_index", embeddings, allow_dangerous_deserialization=True)
    
    llm = ChatGroq(
        api_key="Key!!!!!!!!", # ì œê³µí•´ì£¼ì‹  í‚¤ ì‚¬ìš© (ë³´ì•ˆìƒ ì•ë¶€ë¶„ë§Œ í‘œì‹œ)
        model_name="llama-3.1-8b-instant",
        temperature=0.5
    )
    
    return vector_db.as_retriever(search_kwargs={"k": 3}), llm

@st.cache_data
def load_origin_df():
    df = pd.read_csv('./dataset/google_books_dataset.csv')
    df['thumbnail'] = df['thumbnail'].fillna('') # NaN ë¯¸ë¦¬ ì²˜ë¦¬
    return df

retriever, llm = load_resources()
df_origin = load_origin_df()

# app.py ìƒë‹¨ì— ì¶”ê°€
with st.sidebar:
    st.image("https://cdn-icons-png.flaticon.com/512/1903/1903162.png", width=100) # ë„ì„œê´€ ë¡œê³  ëŠë‚Œ
    st.title("Library Settings")
    st.info("í˜„ì¬ 15,000ê¶Œì˜ ì¥ì„œê°€ ë“±ë¡ë˜ì–´ ìˆìŠµë‹ˆë‹¤.")
    
    # ì˜¨ë„ ì¡°ì ˆ ìŠ¬ë¼ì´ë” (ì‚¬ìš©ìê°€ ì§ì ‘ ì •ë°€ë„ ì¡°ì ˆ)
    temp = st.slider("ì‚¬ì„œì˜ ì°½ì˜ì„± (Temperature)", 0.0, 1.0, 0.0, 0.1)
    
    st.divider()
    st.markdown("### ğŸ’¡ ê²€ìƒ‰ íŒ")
    st.caption("- íŠ¹ì • ì¥ë¥´ë¥¼ ë§ì”€í•´ ë³´ì„¸ìš”.\n- ê¸°ë¶„ì— ë§ëŠ” ì±…ì„ ë¬¼ì–´ë³´ì„¸ìš”.")
    
# --- ì´ë¯¸ì§€ ê²€ìƒ‰ í•¨ìˆ˜ ---
def get_book_thumbnail(title):
    try:
        # ê³µë°± ì œê±° í›„ ë¹„êµí•˜ì—¬ ë§¤ì¹­ í™•ë¥  ì—…
        target_row = df_origin[df_origin['title'].str.strip() == str(title).strip()]
        if not target_row.empty:
            url = target_row['thumbnail'].values[0]
            if isinstance(url, str) and url.startswith('http'):
                return url
        return None
    except:
        return None

# 2. RAG ì²´ì¸ ì„¤ì •
qa_prompt = ChatPromptTemplate.from_messages([
    ("system", """ë„ˆëŠ” ì˜¤ì§ ì œê³µëœ [ë„ì„œ ì •ë³´] ë¦¬ìŠ¤íŠ¸ì— ìˆëŠ” ì±…ë“¤ë¡œë§Œ ë‹µë³€í•˜ëŠ” ì „ë¬¸ ì‚¬ì„œì•¼.
    ì‚¬ìš©ìì˜ ì…ë ¥ì— ë”°ë¼ ì•„ë˜ì™€ ê°™ì´ ë‹¤ë¥´ê²Œ í–‰ë™í•´ì¤˜.

    [í–‰ë™ ê·œì¹™]
    1. **ë‹¨ìˆœ ì¸ì‚¬ë‚˜ ì¼ìƒ ëŒ€í™”**: ì‚¬ìš©ìê°€ "ì•ˆë…•", "ë°˜ê°€ì›Œ", "ëˆ„êµ¬ë‹ˆ?" ë“±ì˜ ì¸ì‚¬ë¥¼ í•˜ë©´ ì±…ì„ ì¶”ì²œí•˜ì§€ ë§ê³ , ì¹œì ˆí•˜ê³  ì§§ê²Œ ì¸ì‚¬ë¥¼ ê±´ë„¤ë©° ë¬´ì—‡ì„ ë„ì™€ì¤„ì§€ ë¬¼ì–´ë´.
    2. **ì±… ì¶”ì²œ ìš”ì²­**: ì±…ì— ëŒ€í•œ ì§ˆë¬¸ì´ë‚˜ ì¶”ì²œ ìš”ì²­ì´ ìˆì„ ë•Œë§Œ ë°˜ë“œì‹œ **3ê¶Œì˜ ì±…**ì„ ì„ ì •í•˜ì—¬ ì•„ë˜ [ì¶œë ¥ í˜•ì‹]ìœ¼ë¡œ ë‹µë³€í•´ì¤˜.
    3. ë§Œì•½ ì œê³µëœ ì •ë³´ ì¤‘ì— ì‚¬ìš©ìì˜ ì§ˆë¬¸ê³¼ ê´€ë ¨ëœ ì±…ì´ í•˜ë‚˜ë„ ì—†ë‹¤ë©´, "ì£„ì†¡í•©ë‹ˆë‹¤. í˜„ì¬ ì €í¬ ë„ì„œê´€ ë°ì´í„°ì—ëŠ” ê´€ë ¨ ë„ì„œê°€ ì—†ìŠµë‹ˆë‹¤."ë¼ê³  ë‹µë³€í•´.
    4. ì¶”ì²œí•˜ëŠ” ì±…ì˜ ì œëª©ì€ ë°˜ë“œì‹œ ë°ì´í„°ì…‹ì— ì íŒ ê·¸ëŒ€ë¡œ ì›ë¬¸ìœ¼ë¡œ í‘œê¸°í•´.
    5. ì¶”ì²œ ë„ì„œì˜ ì œëª©ì€ ì˜ë¬¸ ì œëª©ì´ ìˆìœ¼ë©´ ì˜ë¬¸ì„ ìš°ì„ í•˜ê³ , ì—†ìœ¼ë©´ í•œê¸€ì„ ì¨.

    [ì¶”ì²œ ë„ì„œ ì¶œë ¥ í˜•ì‹]
    1. **ë„ì„œ ì œëª©** (ì €ì) 
    - ğŸ·ï¸ **í•µì‹¬ í‚¤ì›Œë“œ**: #í‚¤ì›Œë“œ1 #í‚¤ì›Œë“œ2
    - ğŸ“ **í•œ ì¤„ ìš”ì•½**: í•µì‹¬ ë‚´ìš©ê³¼ ì¶”ì²œ ì´ìœ  ì •ë¦¬
    (í•­ëª© ê°„ ì¤„ë°”ê¿ˆì„ ì² ì €íˆ ì§€ì¼œì„œ ê°€ë…ì„±ì„ ë†’ì—¬ì¤˜.)

    ë§ˆì§€ë§‰ì— "ë” ê¶ê¸ˆí•œ ì±…ì´ ìˆìœ¼ì‹ ê°€ìš”?"ë¼ê³  ì§§ê²Œ ë§ˆë¬´ë¦¬í•´ì¤˜."""),
    MessagesPlaceholder(variable_name="chat_history"),
    ("human", "ë„ì„œ ì •ë³´: {context}\n\nì‚¬ìš©ì ì§ˆë¬¸: {input}")
])
rag_chain = (
    RunnablePassthrough.assign(context=lambda x: "\n\n".join([d.page_content for d in retriever.invoke(x["input"])]))
    | qa_prompt | llm | StrOutputParser()
)

        
# 3. ì±„íŒ… UI ë° ë¡œì§
if "messages" not in st.session_state:
    st.session_state.messages = []

# ê¸°ì¡´ ëŒ€í™” ë‚´ì—­ ì¶œë ¥
for m in st.session_state.messages:
    with st.chat_message(m["role"]):
        st.markdown(m["content"])

# ì‚¬ìš©ì ì…ë ¥ ì²˜ë¦¬
if prompt := st.chat_input("ì±…ì— ëŒ€í•´ ë¬¼ì–´ë³´ì„¸ìš”!"):
    st.session_state.messages.append({"role": "user", "content": prompt})
    with st.chat_message("user"):
        st.markdown(prompt)

    with st.chat_message("assistant"):
        # 1. ë¬¸ì„œ ë¨¼ì € ê²€ìƒ‰ (ì´ê²Œ ë°˜ë“œì‹œ ìœ„ì— ìˆì–´ì•¼ docs ì •ì˜ ì—ëŸ¬ê°€ ì•ˆ ë‚¨)
        docs = retriever.invoke(prompt) 
        
        response_placeholder = st.empty()
        full_response = ""
        
        # 2. ë‹µë³€ ìƒì„±
        for chunk in rag_chain.stream({"input": prompt, "chat_history": st.session_state.messages[:-1]}):
            full_response += chunk
            response_placeholder.markdown(full_response + "â–Œ")
        response_placeholder.markdown(full_response)
        
        # 3. ì´ë¯¸ì§€ ì¶œë ¥ (ì¸ì‚¬ë§ì´ ì•„ë‹ ë•Œë§Œ)
        if "1." in full_response:
            st.write("---")
            st.markdown("#### ğŸ“– ì¶”ì²œ ë„ì„œ ì´ë¯¸ì§€")
            
            # ë‹µë³€ í…ìŠ¤íŠ¸ì—ì„œ [ì œëª©] í˜•íƒœë¥¼ ì¶”ì¶œí•˜ê±°ë‚˜, 
            # ê²€ìƒ‰ëœ docs ì¤‘ ë‹µë³€ì— ì´ë¦„ì´ ì–¸ê¸‰ëœ ì±…ë“¤ë§Œ í•„í„°ë§
            recommended_docs = [d for d in docs if d.metadata.get('title') in full_response]
            
            if recommended_docs:
                cols = st.columns(len(recommended_docs))
                for i, doc in enumerate(recommended_docs):
                    title = doc.metadata.get('title')
                    img_url = get_book_thumbnail(title)
                    with cols[i]:
                        if img_url:
                            st.image(img_url, use_container_width=True)
                        else:
                            st.info("ì´ë¯¸ì§€ ì¤€ë¹„ ì¤‘")
                        st.caption(f"**{title}**")

    st.session_state.messages.append({"role": "assistant", "content": full_response})