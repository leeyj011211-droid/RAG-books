import gradio as gr
import pandas as pd
import re
from langchain_groq import ChatGroq
from langchain_community.vectorstores import FAISS
from langchain_huggingface import HuggingFaceEmbeddings
from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder
from langchain_core.output_parsers import StrOutputParser

# --- [1] ë¦¬ì†ŒìŠ¤ ë¡œë“œ ë° ì „ì²˜ë¦¬ ---
MY_GROQ_KEY = "Key!!!!!!!!" # ë³¸ì¸ì˜ ì‹¤ì œ í‚¤ ì…ë ¥

embeddings = HuggingFaceEmbeddings(model_name="intfloat/multilingual-e5-small", encode_kwargs={'normalize_embeddings': True})
vector_db = FAISS.load_local("faiss_book_index", embeddings, allow_dangerous_deserialization=True)
retriever = vector_db.as_retriever(search_kwargs={"k": 3})
llm = ChatGroq(api_key=MY_GROQ_KEY, model_name="llama-3.1-8b-instant", temperature=0.0)

# ë°ì´í„° ë¡œë“œ ë° ê²°ì¸¡ì¹˜ ë°©ì–´
df_origin = pd.read_csv('./dataset/google_books_dataset.csv')
df_origin['thumbnail'] = df_origin['thumbnail'].fillna('')
# ì œëª©(title) ì—´ì— ìˆ«ìê°€ ìˆê±°ë‚˜ ë¹„ì–´ìˆëŠ” ê²½ìš°ë¥¼ ëŒ€ë¹„í•´ ëª¨ë‘ ë¬¸ìì—´ë¡œ ê°•ì œ ë³€í™˜
df_origin['title'] = df_origin['title'].astype(str).fillna('Unknown Title')

def get_book_info(title_to_find):
    if not title_to_find or pd.isna(title_to_find):
        return None
    
    # [ì—ëŸ¬ ë°©ì§€ í•µì‹¬] ì…ë ¥ëœ ì œëª©ì„ ë¬¸ìì—´ë¡œ ë³€í™˜í•˜ê³  ì–‘ë ê³µë°± ì œê±°
    search_title = str(title_to_find).strip()
    
    # ë°ì´í„°ì…‹ì—ì„œ ë§¤ì¹­ (ëŒ€ì†Œë¬¸ì ë¬´ì‹œí•˜ì§€ ì•Šê³  ì •í™•íˆ ì¼ì¹˜ í™•ì¸)
    target = df_origin[df_origin['title'].str.strip() == search_title]
    
    if not target.empty:
        url = target['thumbnail'].values[0]
        if isinstance(url, str) and url.startswith('http'):
            return url
    return None

# --- [2] í”„ë¡¬í”„íŠ¸ ìˆ˜ì • (Streamlit ìŠ¤íƒ€ì¼ ì ìš©) ---
qa_prompt = ChatPromptTemplate.from_messages([
    ("system", """ë„ˆëŠ” 15,000ê¶Œì˜ ì¥ì„œë¥¼ ë³´ìœ í•œ ë„ì„œê´€ì˜ 'ìˆ˜ì„ ì‚¬ì„œ'ì•¼. 
    [ì¶œë ¥ ê·œì¹™]
    1. ë°˜ë“œì‹œ ì œê³µëœ ë„ì„œ ì •ë³´ ë‚´ì—ì„œë§Œ ë‹µë³€í•´.
    2. ì±… ì œëª©ì€ ë¬´ì¡°ê±´ **[í•œê¸€ ì œëª© (English Title)]** í˜•ì‹ìœ¼ë¡œ í‘œê¸°í•´.
    3. ì¶”ì²œì€ í•­ìƒ 3ê¶Œì„ ì¶”ì²œ í•˜ê³ , ê° ì±…ë§ˆë‹¤ ì¶”ì²œ ì´ìœ ë¥¼ ì‚¬ì„œì²˜ëŸ¼ ì¹œì ˆí•˜ê²Œ ì„¤ëª…í•´ì¤˜.
    4. ë‹µë³€ì€ í•œêµ­ì–´ë¡œ í•˜ë˜, ì „ë¬¸ì ì´ê³  ë”°ëœ»í•œ ëŠë‚Œì„ ìœ ì§€í•´."""),
    MessagesPlaceholder(variable_name="chat_history"),
    ("human", "ë„ì„œ ì •ë³´: {context}\n\nì‚¬ìš©ì ì§ˆë¬¸: {input}")
])
rag_chain = qa_prompt | llm | StrOutputParser()

# --- [3] ì‘ë‹µ í•¨ìˆ˜ ---
def respond(message, chat_history):
    docs = retriever.invoke(message)
    context = "\n\n".join([d.page_content for d in docs])
    
    history_langchain = []
    for msg in chat_history:
        role = "human" if msg["role"] == "user" else "ai"
        history_langchain.append((role, msg["content"]))
    
    chat_history.append({"role": "user", "content": message})
    chat_history.append({"role": "assistant", "content": ""})
    
    full_response = ""
    for chunk in rag_chain.stream({"input": message, "chat_history": history_langchain, "context": context}):
        full_response += chunk
        chat_history[-1]["content"] = full_response
        yield chat_history, [] 

    # ì´ë¯¸ì§€ ë§¤ì¹­ (ì—ëŸ¬ ë°©ì–´í˜•)
    images = []
    # í…ìŠ¤íŠ¸ ë‚´ì—ì„œ [ì œëª© (ì˜ì–´)] íŒ¨í„´ ì¶”ì¶œ
    pattern = r'\[(.*?)\s*\((.*?)\)\]'
    found_titles = re.findall(pattern, full_response)
    
    for kor_t, eng_t in found_titles:
        img_url = get_book_info(kor_t)
        if img_url:
            images.append((img_url, kor_t))
    
    # í˜¹ì‹œ íŒ¨í„´ìœ¼ë¡œ ëª» ì°¾ì•˜ë‹¤ë©´ Docs ìì²´ ì œëª©ìœ¼ë¡œ ì¬ì‹œë„
    if not images:
        for d in docs:
            t = d.metadata.get('title')
            url = get_book_info(t)
            if url: images.append((url, t))
            
    yield chat_history, images[:3]

# --- [4] ê³ ê¸‰ UI ë””ìì¸ (CSS) ---
theme = gr.themes.Soft(
    primary_hue="blue",
    secondary_hue="slate",
    font=[gr.themes.GoogleFont("Noto Sans KR"), "ui-sans-serif", "system-ui"],
)

with gr.Blocks(theme=theme) as demo:
    gr.Markdown("<h1 style='text-align: center; color: #1a365d;'>ğŸ“š AI ì§€ëŠ¥í˜• ì„œê°€</h1>")
    gr.Markdown("<p style='text-align: center;'>ë‹¹ì‹ ì˜ ì·¨í–¥ì„ ë¶„ì„í•˜ì—¬ ìµœì ì˜ ë„ì„œë¥¼ íë ˆì´íŒ…í•©ë‹ˆë‹¤.</p>")
    
    with gr.Row():
        with gr.Column(scale=4):
            chatbot = gr.Chatbot(label="ì‚¬ì„œì™€ ëŒ€í™”", height=600)
            with gr.Row():
                msg = gr.Textbox(placeholder="ì–´ë–¤ ì±…ì„ ì›í•˜ì‹œë‚˜ìš”? (ì˜ˆ: ìœ„ë¡œê°€ ë˜ëŠ” ì†Œì„¤)", show_label=False, scale=9)
                submit_btn = gr.Button("ë³´ë‚´ê¸°", variant="primary", scale=1)
            clear = gr.Button("ëŒ€í™” ì´ˆê¸°í™”", variant="secondary")
            
        with gr.Column(scale=2):
            gr.Markdown("### ğŸ“– ì¶”ì²œ ë„ì„œ ê°¤ëŸ¬ë¦¬")
            gallery = gr.Gallery(label="í‘œì§€", columns=1, rows=3, height=600, object_fit="contain")

    # ì´ë²¤íŠ¸ ì—°ê²°
    msg.submit(respond, [msg, chatbot], [chatbot, gallery])
    msg.submit(lambda: "", None, msg)
    submit_btn.click(respond, [msg, chatbot], [chatbot, gallery])
    submit_btn.click(lambda: "", None, msg)
    clear.click(lambda: ([], []), None, [chatbot, gallery])

if __name__ == "__main__":
    demo.launch()